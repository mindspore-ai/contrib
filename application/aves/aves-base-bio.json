{
    "feat_extract_norm": "group",
    "conv_dim": [512, 512, 512, 512, 512, 512, 512],
    "conv_kernel": [10, 3, 3, 3, 3, 2, 2],
    "conv_stride": [5, 2, 2, 2, 2, 2, 2],
    "conv_bias": false,
    "hidden_size": 768,
    "feat_proj_dropout": 0.1,
    "num_conv_pos_embeddings": 128,
    "num_conv_pos_embedding_groups": 16,
    "num_hidden_layers": 12,
    "num_attention_heads": 12,
    "attention_dropout": 0.1,
    "intermediate_size": 3072,
    "activation_dropout": 0,
    "hidden_dropout": 0.1,
    "do_stable_layer_norm": false,
    "layerdrop": 0.05
}