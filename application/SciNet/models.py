import mindspore.nn as nn
import mindspore.ops as ops
from mindspore import Tensor
import mindspore

class SciNet(nn.Cell):
	def __init__(self, input_dim, output_dim, latent_dim, layer_dim):
		"""Initialize SciNet Model.
		
		Params
		======
			input_dim (int): number of inputs
			output_dim (int): number of outputs
			latent_dim (int): number of latent neurons
			Layer_dim (int): number of neurons in hidden layers
		"""
		super(SciNet, self).__init__()
		self.latent_dim = latent_dim
		self.enc1 = nn.Dense(input_dim, layer_dim)
		self.enc2 = nn.Dense(layer_dim, layer_dim)
		self.latent = nn.Dense(layer_dim, latent_dim*2)
		self.dec1 = nn.Dense(latent_dim+1, layer_dim)
		self.dec2 = nn.Dense(layer_dim,layer_dim)
		self.out = nn.Dense(layer_dim, output_dim)
 
	def encoder(self, x):
	
		z = ops.elu(self.enc1(x))
		z = ops.elu(self.enc2(z))
		z = self.latent(z)
		self.mu = z[:, 0:self.latent_dim]
		self.log_sigma = z[:, self.latent_dim:]
		self.sigma = mindspore.ops.exp(self.log_sigma)

		# Use reparametrization trick to sample from gaussian
		eps = mindspore.ops.randn(x.shape[0], self.latent_dim)
		z_sample = self.mu + self.sigma * eps        

		# Compute KL loss
		self.kl_loss = kl_divergence(self.mu, self.log_sigma, dim=self.latent_dim)

		return z_sample
	
	def decoder(self, z):
		x = ops.elu(self.dec1(z))
		x = ops.elu(self.dec2(x))        
		return self.out(x)

	def construct(self, obs):
		"""
		Constructs the forward pass of the model.
		Parameters:
        - obs: Input observations, shape (batch_size, input_dim+1).
               The last column is treated as a separate feature (query).

    	Returns:
        - pred: Predicted outputs generated by the decoder based on the latent representation.
		"""
		q = obs[:, -1 ].reshape(obs.shape[0], 1)
		obs = obs[:,0:-1]
		self.latent_r = self.encoder(obs) 
		dec_input = mindspore.ops.cat( (q, self.latent_r), 1)
		pred = self.decoder(dec_input)
		return pred


def kl_divergence( means, log_sigma, dim, target_sigma=0.1):
	"""
    Computes Kullbackâ€“Leibler divergence for arrays of mean and log(sigma)
    """
	target_sigma = Tensor([target_sigma], mindspore.float32)
	return 1 / 2. * mindspore.ops.mean(mindspore.ops.mean(1 / target_sigma**2 * means**2 +
			mindspore.ops.exp(2 * log_sigma) / target_sigma**2 - 2 * log_sigma 
			+ 2 * mindspore.ops.log(target_sigma), axis=1) - dim)


   