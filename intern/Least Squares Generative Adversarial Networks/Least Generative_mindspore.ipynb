{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d1b89c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#访问数据集文件问题\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(\"DCGAN\")\n",
    "parser.add_argument('--dataset_dir', type=str, default=\"\") # dataset directory\n",
    "parser.add_argument('--result_dir', type=str, default='') # log image directory\n",
    "parser.add_argument('--batch_size', type=int, default=64) # batch size\n",
    "parser.add_argument('--n_epoch', type=int, default=20) # epoch size\n",
    "parser.add_argument('--n_cpu', type=int, default=4) # num of process(for use worker)\n",
    "parser.add_argument('--log_iter', type=int, default=1000) # print log message and save image per log_iter\n",
    "parser.add_argument('--nz', type=int, default=100)  # noise dimension\n",
    "parser.add_argument('--nc', type=int, default=3)    # input and out channel\n",
    "parser.add_argument('--ndf', type=int, default=64)  # number of Discriminator's feature map dimension\n",
    "parser.add_argument('--ngf', type=int, default=64)  # number of Generator's feature map dimension\n",
    "parser.add_argument('--lr', type=float, default=0.0002) # learning rate\n",
    "parser.add_argument('--device',type=str,default=\"NPU\")#device \n",
    "parser.add_argument('--beta', type=float, default=0.5)\n",
    "parser.add_argument('--criterion', type=str, default='BCE') # BCE / MSE\n",
    "parser.add_argument('--tanh', action='store_true') # Use tanh end of generator\n",
    "config, _ = parser.parse_known_args()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f39e2",
   "metadata": {},
   "source": [
    "构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d409bc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import os\n",
    "class Generator(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        main = [\n",
    "            nn.Conv2dTranspose(in_channels=config.nz,out_channels= config.ngf * 8,kernel_size= 4,stride=1,padding=0,pad_mode=\"pad\", has_bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(in_channels=config.ngf * 8,out_channels= config.ngf * 4,kernel_size= 4,stride= 2,padding= 1,pad_mode=\"pad\", has_bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(in_channels=config.ngf * 4,out_channels= config.ngf * 2,kernel_size=  4,stride= 2,padding= 1,pad_mode=\"pad\", has_bias=False),\n",
    "            nn.BatchNorm2d(config.ngf * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(in_channels=config.ngf * 2,out_channels= config.ngf,kernel_size=  4,stride= 2,padding= 1,pad_mode=\"pad\", has_bias=False),\n",
    "            nn.BatchNorm2d(config.ngf),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2dTranspose(in_channels=config.ngf,out_channels= config.nc,kernel_size=  4,stride= 2, padding=1,pad_mode=\"pad\", has_bias=False),\n",
    "        ]\n",
    "\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.main = nn.SequentialCell(*main)\n",
    "\n",
    "    def construct(self, x):\n",
    "        out=self.main(x)\n",
    "        if config.tanh:\n",
    "            out=self.tanh(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        main = [\n",
    "            nn.Conv2d(in_channels=config.nc,out_channels=config.ndf,kernel_size=4,stride= 2,padding= 1, has_bias=False,pad_mode=\"pad\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=config.ndf,out_channels= config.ndf * 2,kernel_size= 4,stride= 2,padding= 1,has_bias=False,pad_mode=\"pad\"),\n",
    "            nn.BatchNorm2d(config.ndf * 2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=config.ndf * 2,out_channels= config.ndf * 4,kernel_size= 4,stride= 2,padding= 1, has_bias=False,pad_mode=\"pad\"),\n",
    "            nn.BatchNorm2d(config.ndf * 4),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=config.ndf * 4,out_channels= config.ndf * 8,kernel_size= 4,stride= 2,padding= 1,has_bias=False,pad_mode=\"pad\"),\n",
    "            nn.BatchNorm2d(config.ndf * 8),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(in_channels=config.ndf * 8,out_channels=1,kernel_size= 4,stride= 1,padding= 0,has_bias=False,pad_mode=\"pad\"),\n",
    "        ]\n",
    "     \n",
    "\n",
    "        self.main = nn.SequentialCell(*main)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def construct(self, x):\n",
    "        out=self.main(x)\n",
    "        out=out.reshape(-1,1)\n",
    "        if config.criterion=='BCE':\n",
    "            out=self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91640f15",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def show_generated_images(fake_images):\n",
    "        #同时获得最小值和最大值\n",
    "        min_val,max_val=ops.aminmax(fake_images)\n",
    "        #解决StubTensor情况，Tensor->float\n",
    "        min_val = min_val.asnumpy()\n",
    "        max_val = max_val.asnumpy()\n",
    "        min_mat=Tensor(np.full(fake_images.shape,min_val))\n",
    "        ret_mat=Tensor(np.full(fake_images.shape,255))\n",
    "        div_mat=Tensor(np.full(fake_images.shape,max_val-min_val))\n",
    "        # 映射到 [0, 255]\n",
    "        fake_images=ops.sub(fake_images,min_mat)\n",
    "        fake_images=ops.div(fake_images,div_mat)\n",
    "        fake_images=ops.mul(fake_images,ret_mat)\n",
    "        # 将 Tensor 转换为 numpy 数组\n",
    "        fake_images_np = fake_images.asnumpy().transpose(0, 2, 3, 1)  # 调整维度以适应 matplotlib\n",
    "        # 转换为 uint8 类型\n",
    "        fake_images_np = fake_images_np.astype(np.uint8) \n",
    "        # 展示图片\n",
    "        fig, axes = plt.subplots(1, min(config.batch_size, 10), figsize=(10, 2))\n",
    "        for ax, img in zip(axes, fake_images_np[:10]):\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f917ac08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import mindspore.experimental.optim as optim\n",
    "import mindspore as ms\n",
    "import mindspore.dataset as msda\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mindspore import Tensor,ops,context,Parameter,value_and_grad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.real_best_loss=float('inf')\n",
    "        self.fake_best_loss=float('inf')\n",
    "\n",
    "#         if config.device == 'GPU':\n",
    "#             context.set_context(device_target=\"GPU\")\n",
    "#         else:\n",
    "#             context.set_context(device_target=\"CPU\")\n",
    "\n",
    "        self.optimizer_g = nn.Adam(self.generator.trainable_params(), learning_rate=config.lr, beta1=config.beta,beta2=0.999)\n",
    "        self.optimizer_d = nn.Adam(self.discriminator.trainable_params(), learning_rate=config.lr, beta1=config.beta,beta2=0.999)\n",
    "        \n",
    "    def forward_fn_g(self,data, label):\n",
    "        loss = self.loss(data, label)\n",
    "        return loss,()#,logits\n",
    "    \n",
    "    def forward_fn_d(self,data1, label1,data2,label2):\n",
    "        loss = self.loss(data1, label1)+self.loss(data2,label2)\n",
    "        return loss,()#,logits1,logits2\n",
    "    \n",
    "    def grad_fn_g(self,d_fake,label_real):\n",
    "        fs=value_and_grad(self.forward_fn_g, None,self.optimizer_g.parameters, has_aux=True)\n",
    "        (loss, _), grads=fs(d_fake,label_real)\n",
    "        return loss,grads\n",
    "    \n",
    "    def grad_fn_d(self,d_real,label_real,d_fake,label_fake):\n",
    "        fs=value_and_grad(self.forward_fn_d, None,self.optimizer_d.parameters, has_aux=True)\n",
    "        (loss, _), grads=fs(d_real, label_real,d_fake, label_fake)\n",
    "        return loss,grads\n",
    "  \n",
    "    \n",
    "    def train_d(self,label_real,real,label_fake,fake):\n",
    "        d_real = self.discriminator(real)\n",
    "        d_fake= self.discriminator(ops.stop_gradient(fake))\n",
    "        d_real=Tensor(d_real)\n",
    "        d_fake=Tensor(d_fake)\n",
    "        loss, grads = self.grad_fn_d(d_real, label_real,d_fake, label_fake)\n",
    "        self.optimizer_d(grads)\n",
    "        return loss,d_real\n",
    "\n",
    "    def train_g(self,fake,label_real):\n",
    "        d_fake = self.discriminator(fake)\n",
    "        loss, grads = self.grad_fn_g(d_fake, label_real)\n",
    "        self.optimizer_g(grads)\n",
    "        return loss,d_fake\n",
    "\n",
    "\n",
    "    def train(self, dataloader):\n",
    "         # 创建噪声张量\n",
    "        noise = Tensor(np.random.randn(config.batch_size, config.nz, 1, 1), dtype=ms.float32)\n",
    "\n",
    "        # 创建真实标签\n",
    "        label_real = Tensor(np.ones((config.batch_size, 1)), dtype=ms.float32)\n",
    "\n",
    "        # 创建假标签\n",
    "        label_fake = Tensor(np.zeros((config.batch_size, 1)), dtype=ms.float32)\n",
    "        \n",
    "\n",
    "        for epoch in range(config.n_epoch):\n",
    "            for i,(data, _) in enumerate(dataloader,0):\n",
    "                #训练需要带入数据，否则只是训练噪声\n",
    "                noise = ops.standard_normal(noise.shape)\n",
    "                noise=Tensor(noise)\n",
    "#                 print(noise.shape)\n",
    "                \n",
    "                # Train Discriminator\n",
    "\n",
    "                real=Parameter(Tensor(data,dtype=ms.float32),requires_grad=True)\n",
    "#                 print(real.shape)\n",
    "                \n",
    "                fake = self.generator(noise)\n",
    "#                 print(fake.shape)\n",
    "                fake=Tensor(fake)\n",
    "#                 noise.reshape(fake.shape)\n",
    "                loss_d,d_real=self.train_d(label_real,real,label_fake,fake)\n",
    "                loss_g,d_fake=self.train_g(fake,label_real)\n",
    "\n",
    "\n",
    "                if i % config.log_iter == 0:\n",
    "                    print(\"[Epoch {:03d}] ({}/{}) d_real: {}, d_fake: {}\".format(epoch, i, len(dataloader),d_real.mean(), d_fake.mean()))\n",
    "                    if loss_d<self.real_best_loss:\n",
    "                        self.real_best=loss_d\n",
    "                        ms.save_checkpoint(self.discriminator,'discriminator_best.ckpt')\n",
    "                    if loss_g<self.fake_best_loss:\n",
    "                        self.fake_best=loss_g\n",
    "                        ms.save_checkpoint(self.generator,'generator_best.ckpt')\n",
    "                    #保存并打印图像\n",
    "                    show_generated_images(fake)\n",
    "                                                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f41ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #给出示例文件夹\n",
    "    config.dataset_dir=\"CeleA\"\n",
    "    config.result_dir=\"result\"\n",
    "    transform=msda.transforms.Compose([\n",
    "        msda.vision.Resize((64,64)),\n",
    "        msda.vision.ToTensor(),\n",
    "        msda.vision.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5),False)])\n",
    "    context.set_context()#清理内存\n",
    "    #dset = dset.map(transform,[\"image\"])\n",
    "    ms_dataloader = msda.CelebADataset(config.dataset_dir, usage='all', decode=True,shuffle=True,num_parallel_workers=config.n_cpu,num_samples=config.batch_size)\n",
    "    ms_dataloader = ms_dataloader.map(transform, [\"image\"])\n",
    "    ms_dataloader = ms_dataloader.batch(config.batch_size)\n",
    "    ms.set_context(device_target=\"Ascend\")\n",
    "    trainer = Trainer()\n",
    "    trainer.train(ms_dataloader)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ms.ms_memory_recycle()\n",
    "    main()\n",
    "    if os.path.exists(\"generator_best.ckpt\"):\n",
    "        #引用生成器类\n",
    "        gen=Generator()\n",
    "        param_dict_g=ms.load_checkpoint(\"generator_best.ckpt\",Generator())\n",
    "        ms.load_param_into_net(gen, param_dict_g)\n",
    "        noise=Tensor(np.random.randn(config.batch_size, config.nz, 1, 1), dtype=ms.float32)\n",
    "        noise = ops.standard_normal(noise.shape)\n",
    "        noise=Tensor(noise)\n",
    "        fake_images=gen(noise)\n",
    "        show_generated_images(fake_images)\n",
    "    #后续补充绘图函数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
