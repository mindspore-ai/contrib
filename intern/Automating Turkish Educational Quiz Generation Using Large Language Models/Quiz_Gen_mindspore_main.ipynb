{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce820d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping mindnlp as it is not installed.\u001b[0m\n",
      "Found existing installation: mindspore 2.3.0\n",
      "Uninstalling mindspore-2.3.0:\n",
      "  Successfully uninstalled mindspore-2.3.0\n",
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Collecting mindspore==2.4.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/mindspore/2.4.0/mindspore-2.4.0-cp39-none-any.whl (333.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 333.7 MB 74.8 MB/s eta 0:00:01     |███████████████▋                | 163.0 MB 67.4 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (10.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (1.22.0)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (1.10.1)\n",
      "Collecting safetensors>=0.4.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/safetensors/0.5.2/safetensors-0.5.2-cp38-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 55.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (3.20.2)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (2.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (1.6.3)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (5.9.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore==2.4.0) (24.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore==2.4.0) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore==2.4.0) (0.38.4)\n",
      "Installing collected packages: safetensors, mindspore\n",
      "Successfully installed mindspore-2.4.0 safetensors-0.5.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\n",
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Collecting datasets\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/datasets/3.3.0/datasets-3.3.0-py3-none-any.whl (484 kB)\n",
      "\u001b[K     |████████████████████████████████| 484 kB 42.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (1.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (0.24.2)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/multiprocess/0.70.16/multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 62.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pyarrow/19.0.0/pyarrow-19.0.0-cp39-cp39-manylinux_2_28_aarch64.whl (40.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.5 MB 38.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (3.15.4)\n",
      "Collecting aiohttp\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/aiohttp/3.11.12/aiohttp-3.11.12-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 36.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.32.2\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/requests/2.32.3/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 53.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/xxhash/3.5.0/xxhash-3.5.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 60.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (2024.6.1)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets) (1.3.5)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/aiosignal/1.3.2/aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/yarl/1.18.3/yarl-1.18.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (317 kB)\n",
      "\u001b[K     |████████████████████████████████| 317 kB 36.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/aiohappyeyeballs/2.4.6/aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/frozenlist/1.5.0/frozenlist-1.5.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 64.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/propcache/0.2.1/propcache-0.2.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 69.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/multidict/6.1.0/multidict-6.1.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/async-timeout/5.0.1/async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: propcache, multidict, frozenlist, yarl, async-timeout, aiosignal, aiohappyeyeballs, requests, aiohttp, xxhash, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 12.0.1\n",
      "    Uninstalling pyarrow-12.0.1:\n",
      "      Successfully uninstalled pyarrow-12.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mindformers 1.2.0 requires pyarrow==12.0.1, but you have pyarrow 19.0.0 which is incompatible.\n",
      "modelarts 1.4.28 requires lxml==5.1.0, but you have lxml 4.9.3 which is incompatible.\n",
      "modelarts 1.4.28 requires matplotlib==3.5.2, but you have matplotlib 3.5.1 which is incompatible.\n",
      "modelarts 1.4.28 requires prettytable<=3.7.0, but you have prettytable 3.10.2 which is incompatible.\n",
      "modelarts 1.4.28 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
      "modelarts 1.4.28 requires tqdm<=4.66.1, but you have tqdm 4.66.4 which is incompatible.\n",
      "modelarts 1.4.28 requires typing-extensions==4.7.1, but you have typing-extensions 4.12.2 which is incompatible.\n",
      "modelarts 1.4.28 requires urllib3==1.26.18, but you have urllib3 1.26.7 which is incompatible.\u001b[0m\n",
      "Successfully installed aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.3.0 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-19.0.0 requests-2.32.3 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Collecting git+https://github.com/mindspore-lab/mindnlp.git\n",
      "  Cloning https://github.com/mindspore-lab/mindnlp.git to /tmp/pip-req-build-xyotdokh\n",
      "  Running command git clone -q https://github.com/mindspore-lab/mindnlp.git /tmp/pip-req-build-xyotdokh\n",
      "Requirement already satisfied: mindspore>=2.2.14 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (4.66.4)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (2.32.3)\n",
      "Requirement already satisfied: datasets in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (3.3.0)\n",
      "Collecting evaluate\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/evaluate/0.4.3/evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.19.1\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/tokenizers/0.19.1/tokenizers-0.19.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 54.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: safetensors in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (0.2.0)\n",
      "Requirement already satisfied: regex in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (2024.7.24)\n",
      "Requirement already satisfied: addict in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (2.4.0)\n",
      "Requirement already satisfied: ml_dtypes in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (0.4.0)\n",
      "Collecting pyctcdecode\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pyctcdecode/0.5.0/pyctcdecode-0.5.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pytest==7.2.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pytest/7.2.0/pytest-7.2.0-py3-none-any.whl (316 kB)\n",
      "\u001b[K     |████████████████████████████████| 316 kB 64.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=10.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindnlp==0.4.1) (10.0.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (23.2.0)\n",
      "Requirement already satisfied: iniconfig in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (1.2.2)\n",
      "Requirement already satisfied: packaging in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pytest==7.2.0->mindnlp==0.4.1) (24.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from tokenizers==0.19.1->mindnlp==0.4.1) (0.24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.4.1) (4.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.4.1) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.19.1->mindnlp==0.4.1) (2024.6.1)\n",
      "Requirement already satisfied: protobuf>=3.13.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (3.20.2)\n",
      "Requirement already satisfied: astunparse>=1.6.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (1.6.3)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (1.10.1)\n",
      "Requirement already satisfied: psutil>=5.6.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (5.9.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (1.22.0)\n",
      "Requirement already satisfied: asttokens>=2.0.4 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from mindspore>=2.2.14->mindnlp==0.4.1) (2.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from asttokens>=2.0.4->mindspore>=2.2.14->mindnlp==0.4.1) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from astunparse>=1.6.3->mindspore>=2.2.14->mindnlp==0.4.1) (0.38.4)\n",
      "Requirement already satisfied: xxhash in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (0.70.16)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (1.3.5)\n",
      "Requirement already satisfied: aiohttp in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from datasets->mindnlp==0.4.1) (3.11.12)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (2.4.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from aiohttp->datasets->mindnlp==0.4.1) (1.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.1) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.1) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from requests->mindnlp==0.4.1) (2.0.12)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.4.1) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (from pandas->datasets->mindnlp==0.4.1) (2.9.0.post0)\n",
      "Collecting pygtrie<3.0,>=2.1\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/pygtrie/2.5.0/pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
      "Collecting hypothesis<7,>=6.14\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/hypothesis/6.125.3/hypothesis-6.125.3-py3-none-any.whl (480 kB)\n",
      "\u001b[K     |████████████████████████████████| 480 kB 37.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers<3.0.0,>=2.1.0\n",
      "  Downloading http://pip.modelarts.private.com:8888/repository/pypi/packages/sortedcontainers/2.4.0/sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: mindnlp\n",
      "  Building wheel for mindnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mindnlp: filename=mindnlp-0.4.1-py3-none-any.whl size=8744125 sha256=49387edde6a027e07760b87ab03a92aa4cc6aaeaef0c897fb2c9e8fdc2b81af2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-lktyjtdk/wheels/df/6e/b6/2249ba3fb449f11ef76f1a7588a314c2880c166bad79e43a41\n",
      "Successfully built mindnlp\n",
      "Installing collected packages: sortedcontainers, pygtrie, hypothesis, tokenizers, pytest, pyctcdecode, evaluate, mindnlp\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.0\n",
      "    Uninstalling tokenizers-0.15.0:\n",
      "      Successfully uninstalled tokenizers-0.15.0\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 7.1.2\n",
      "    Uninstalling pytest-7.1.2:\n",
      "      Successfully uninstalled pytest-7.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mindformers 1.2.0 requires pyarrow==12.0.1, but you have pyarrow 19.0.0 which is incompatible.\n",
      "mindformers 1.2.0 requires tokenizers==0.15.0, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\n",
      "Successfully installed evaluate-0.4.3 hypothesis-6.125.3 mindnlp-0.4.1 pyctcdecode-0.5.0 pygtrie-2.5.0 pytest-7.2.0 sortedcontainers-2.4.0 tokenizers-0.19.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Looking in indexes: http://pip.modelarts.private.com:8888/repository/pypi/simple\n",
      "Requirement already satisfied: safetensors in /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages (0.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping soundfile as it is not installed.\u001b[0m\n",
      "Found existing installation: mindformers 1.2.0\n",
      "Uninstalling mindformers-1.2.0:\n",
      "  Successfully uninstalled mindformers-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!rm -rf output lost+found kernel_meta\n",
    "!pip uninstall mindnlp mindspore -y\n",
    "# !git clone https://hf-mirror.com/Kamyar-zeinalipour/TR_QUIZ_GEN_MULTI_LLAMA7B\n",
    "!pip install mindspore==2.4.0\n",
    "!rm -rf TR_QUIZ_GEN_MULTI_LLAMA7B/adapter_model.safetensors\n",
    "!pip uninstall peft transformers -y\n",
    "!pip install datasets\n",
    "!pip install git+https://github.com/mindspore-lab/mindnlp.git\n",
    "!pip install safetensors\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "if not os.path.exists(\"TR_QUIZ_GEN_MULTI_LLAMA13B/adapter_model.safetensors\") and not os.path.exists(\"TR_QUIZ_GEN_MULTI_LLAMA13B/adapter_model.ckpt\"):\n",
    "    !wget -P TR_QUIZ_GEN_MULTI_LLAMA13B https://hf-mirror.com/Kamyar-zeinalipour/TR_QUIZ_GEN_MULTI_LLAMA13B/resolve/main/adapter_model.safetensors\n",
    "if not os.path.exists(\"TR_QUIZ_GEN_MULTI_LLAMA7B/adapter_model.safetensors\") and not os.path.exists(\"TR_QUIZ_GEN_MULTI_LLAMA7B/adapter_model.ckpt\"):\n",
    "    !wget -P TR_QUIZ_GEN_MULTI_LLAMA7B https://hf-mirror.com/Kamyar-zeinalipour/TR_QUIZ_GEN_MULTI_LLAMA7B/resolve/main/adapter_model.safetensors\n",
    "!pip uninstall soundfile -y\n",
    "!pip uninstall mindformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadad712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mindspore\n",
      "Version: 2.4.0\n",
      "Summary: MindSpore is a new open source deep learning training/inference framework that could be used for mobile, edge and cloud scenarios.\n",
      "Home-page: https://www.mindspore.cn\n",
      "Author: The MindSpore Authors\n",
      "Author-email: contact@mindspore.cn\n",
      "License: Apache 2.0\n",
      "Location: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages\n",
      "Requires: astunparse, pillow, packaging, psutil, numpy, safetensors, protobuf, asttokens, scipy\n",
      "Required-by: mindnlp\n",
      "Name: mindnlp\n",
      "Version: 0.4.1\n",
      "Summary: An open source natural language processing research tool box. Git version: [sha1]:ab20e2e7, [branch]: (HEAD -> master, origin/master, origin/HEAD)\n",
      "Home-page: https://github.com/mindlab-ai/mindnlp/tree/master/\n",
      "Author: MindSpore Team\n",
      "Author-email: None\n",
      "License: Apache 2.0\n",
      "Location: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages\n",
      "Requires: sentencepiece, pyctcdecode, evaluate, tqdm, pillow, datasets, mindspore, tokenizers, safetensors, addict, pytest, requests, ml-dtypes, regex\n",
      "Required-by: \n",
      "\u001b[33mWARNING: Package(s) not found: transformers\u001b[0m\n",
      "Name: tokenizers\n",
      "Version: 0.19.1\n",
      "Summary: None\n",
      "Home-page: None\n",
      "Author: Anthony MOI <m.anthony.moi@gmail.com>\n",
      "Author-email: Nicolas Patry <patry.nicolas@protonmail.com>, Anthony Moi <anthony@huggingface.co>\n",
      "License: None\n",
      "Location: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages\n",
      "Requires: huggingface-hub\n",
      "Required-by: mindnlp\n"
     ]
    }
   ],
   "source": [
    "#!huggingface-cli login \"sgfdoax42skw123\" #更换为自己的key\n",
    "# repokey=\"wsawqqwe123ser\"\n",
    "!pip show mindspore\n",
    "!pip show mindnlp\n",
    "!pip show transformers\n",
    "!pip show tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f77430",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.745.841 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclmdlBundleGetModelId failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclmdlBundleGetModelId\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.745.892 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclmdlBundleLoadFromMem failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclmdlBundleLoadFromMem\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.745.911 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclmdlBundleUnload failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclmdlBundleUnload\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.746.165 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclrtGetMemUceInfo failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtGetMemUceInfo\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.746.183 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclrtDeviceTaskAbort failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtDeviceTaskAbort\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.746.199 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclrtMemUceRepair failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtMemUceRepair\n",
      "[WARNING] GE_ADPT(1578,ffffb50110b0,python):2025-02-16-17:28:36.748.109 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol acltdtCleanChannel failed, result = /usr/local/Ascend/ascend-toolkit/latest/lib64/libacl_tdt_channel.so: undefined symbol: acltdtCleanChannel\n",
      "[WARNING] ME(1578:281473718489264,MainProcess):2025-02-16-17:28:36.893.868 [mindspore/run_check/_check_version.py:396] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 1.317 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/Cython/Compiler/Main.py:384: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/models/graphormer/algos_graphormer.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "[WARNING] ME(1578:281473718489264,MainProcess):2025-02-16-17:28:57.674.560 [mindspore/run_check/_check_version.py:396] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n",
      "[WARNING] ME(1578:281473718489264,MainProcess):2025-02-16-17:28:57.678.886 [mindspore/run_check/_check_version.py:396] Can not find the tbe operator implementation(need by mindspore-ascend). Please check whether the Environment Variable PYTHONPATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install\n"
     ]
    }
   ],
   "source": [
    "#访问数据集文件问题\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd\n",
    "import mindspore as ms\n",
    "from mindspore import nn,context\n",
    "# import mindnlp\n",
    "# from mindnlp.core import no_grad\n",
    "from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from mindnlp.peft import PeftConfig,PeftModel,get_peft_model\n",
    "ms.set_context(mode=ms.PYNATIVE_MODE, device_target=\"Ascend\", save_graphs=False)\n",
    "context.set_auto_parallel_context(parallel_mode=ms.ParallelMode.AUTO_PARALLEL)\n",
    "ms.ms_memory_recycle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e206c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "!echo \"\" > result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d4a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File process ready\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"https://hf-mirror.com//datasets/Kamyar-zeinalipour/Turkish-Quiz-Instruct/data/train-00000-of-00001.parquet\")\n",
    "print(df.info)\n",
    "from datasets import load_dataset\n",
    "# from mindnlp.dataset import load_dataset\n",
    "# ms.dataset.config.set_seed(0)\n",
    "ds = load_dataset(\"Kamyar-zeinalipour/Turkish-Quiz-Instruct\")\n",
    "train=ds[\"train\"]\n",
    "output_file=\"Train-dataset.csv\"\n",
    "# df_selected=das.source.ds.features[[\"content\",\"short_questions\"]]\n",
    "# 将数据转换为 DataFrame\n",
    "df = pd.DataFrame(train)\n",
    "print(df.columns)\n",
    "# 选择需要的列\n",
    "# df_selected = df[[\"content\", \"short_questions\"]]\n",
    "df_selected = df[[\"content\", \"multiple_questions\"]]\n",
    "# 将 DataFrame 写入 CSV 文件\n",
    "df_selected.to_csv(output_file, index=False)\n",
    "print(\"File process ready\")\n",
    "with open(output_file,\"w\") as f:\n",
    "    for ex in train:\n",
    "        ct=ex[\"content\"]\n",
    "        mq=ex[\"multiple_questions\"]\n",
    "        if \"right_answer:\" in mq:\n",
    "            mq_parts = mq.split(\"right_answer:\")\n",
    "            mq = mq_parts[0].strip()  # 取 right_answer 之前的部分，并去除前后空白字符\n",
    "#         sq=ex[\"short_questions\"]\n",
    "#         sb=ex[\"subject\"]\n",
    "#         st=ex[\"subsubtopic\"]\n",
    "        f.write(f\"{ct}\\t{mq}\\n\")\n",
    "print(ds[0])\n",
    "#指定 Parquet 文件的路径\n",
    "# parquet_file_path = 'Turkish-Quiz-Instruct/data/train-00000-of-00001.parquet'\n",
    "\n",
    "# # 读取 Parquet 文件\n",
    "# df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# # 查看数据的前几行\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4888d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer OK\n"
     ]
    }
   ],
   "source": [
    "from safetensors.numpy import load_file\n",
    "import mindspore as ms\n",
    "from mindspore.train.serialization import save_checkpoint\n",
    "import numpy as np\n",
    "# # # if not os.path.exists(\"TR_QUIZ_GEN_MULTI_LLAMA13B/adapter_model.ckpt\"):\n",
    "# # # 加载 .safetensors 文件\n",
    "safetensors_path = \"TR_QUIZ_GEN_MULTI_LLAMA7B/adapter_model.safetensors\"\n",
    "state_dict_numpy = load_file(safetensors_path)\n",
    "\n",
    "# 将 numpy 数组转换为 MindSpore 参数格式\n",
    "params_list = []\n",
    "for name, param_np in state_dict_numpy.items():\n",
    "    # 创建 MindSpore 参数对象\n",
    "    param_np = param_np.astype(np.float16)\n",
    "    ms_param = ms.Parameter(ms.Tensor(param_np), name=name)\n",
    "    params_list.append(ms_param)\n",
    "\n",
    "# 保存为 .ckpt 文件\n",
    "ckpt_path = \"TR_QUIZ_GEN_MULTI_LLAMA7B/adapter_model.ckpt\"\n",
    "save_checkpoint(params_list, ckpt_path)\n",
    "ms.ms_memory_recycle()\n",
    "# !rm -rf TR_QUIZ_GEN_MULTI_LLAMA13B/adapter_model.safetensors\n",
    "print(\"Transfer OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd1ffcb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "MAX_NEW_TOKENS = 8\n",
    "TOP_K = 20\n",
    "TOP_P = 0.9\n",
    "NO_REPEAT_NGRAM_SIZE = 4\n",
    "REPETITION_PENALTY = 1.0\n",
    "\n",
    "def get_code_completion(prompt: str, model, tokenizer, temperature: float) -> str:\n",
    "    \"\"\"Generate code completion for a given prompt\"\"\"\n",
    "    try:\n",
    "        tokenized_input = tokenizer(prompt, return_tensors=\"ms\")\n",
    "        input_ids = tokenized_input[\"input_ids\"]\n",
    "        print(\"input_ids dtype:\", input_ids.dtype)  # 检查是否为 int32/int64\n",
    "        outputs = model.generate(\n",
    "            input_ids=tokenized_input[\"input_ids\"],\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            temperature=temperature,\n",
    "            top_k=TOP_K,\n",
    "            top_p=TOP_P,\n",
    "            do_sample=True,\n",
    "            no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,\n",
    "            repetition_penalty=REPETITION_PENALTY,\n",
    "            output_attentions=False,  # 关闭注意力输出以减少计算\n",
    "    output_hidden_states=False\n",
    "        )\n",
    "#         del tokenized_input\n",
    "#         del input_ids\n",
    "#         gc.collect()\n",
    "        ms.ms_memory_recycle()\n",
    "        return tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]\n",
    "    except Exception as e:\n",
    "#         print(len(str(e)))\n",
    "        print(f\"Error during code generation: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ac949c-65fc-4b6c-8578-842e6cc679bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindnlp.transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import mindspore as ms\n",
    "\n",
    "class SafeLlamaModel(LlamaForCausalLM):  # 继承自 LLaMA 的模型类\n",
    "    def __init__(self, original_model):\n",
    "        super().__init__(original_model.config)\n",
    "        # 复制原模型的参数和子模块\n",
    "        self.load_state_dict(original_model.parameters_dict())\n",
    "        self.model = original_model.model  # LLaMA 的主干网络\n",
    "        self.lm_head = original_model.lm_head  # 输出头\n",
    "\n",
    "    def construct(self, input_ids, **kwargs):\n",
    "        # 调用原模型的前向计算\n",
    "        outputs = self.model(input_ids, **kwargs)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        logits = self.lm_head(hidden_states)\n",
    "        # 强制转换 logits 为 float32\n",
    "        logits = logits.astype(ms.float32)\n",
    "        return logits  # 返回与原模型一致的输出结构\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9202bd7-7a59-4fd8-b778-406d3c50b2d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from mindnlp.transformers import AutoModel\n",
    "def load_model(model_path: str) -> tuple:\n",
    "    \"\"\"Load the pre-trained model and tokenizer\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    print(tokenizer)\n",
    "    config = PeftConfig.from_pretrained(model_path[19:])\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\"modelscope/Llama-2-7b-chat-ms\",mirror=\"modelscope\")\n",
    "    model=PeftModel.from_pretrained(base_model,model_path[19:])\n",
    "    print(\"Load model OK\")\n",
    "    return model, tokenizer\n",
    "\n",
    "def process_input_file(input_file: str) -> pd.DataFrame:\n",
    "    \"\"\"Read the input file and return a pandas DataFrame\"\"\"\n",
    "    return pd.read_csv(input_file, sep=\"\\t\", header=None, names=[\"content\", \"short_questions\"], on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98de3772",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "def generate_code_completions(\n",
    "    model, tokenizer, input_file: str, output_file: str, temperature: float\n",
    ") -> None:\n",
    "    \"\"\"Generate code completions for the input file and save to the output file\"\"\"\n",
    "    df = process_input_file(input_file)\n",
    "    processed_df = pd.DataFrame(columns=[\"prompt\", \"output\"])\n",
    "\n",
    "    try:\n",
    "        processed_df = pd.read_csv(output_file, sep=\"\\t\")\n",
    "        last_index = processed_df.index[-1] if not processed_df.empty else -1\n",
    "    except (FileNotFoundError, pd.errors.EmptyDataError):\n",
    "#         print(\"Error of file\")\n",
    "        last_index = -1\n",
    "    print(f\"Total row:{last_index}\")\n",
    "    for i, row in df.iterrows():\n",
    "        if i <= last_index:\n",
    "            continue\n",
    "\n",
    "        print(\"Row Number:\", i)\n",
    "#         prompt = f'Aşağıdaki materyali okuyun: {row[\"content\"]}，Aşağıdaki soruları cevaplayın:{row[\"multiple_questions\"]}'\n",
    "        prompt = f'{row[\"content\"]}{row[\"short_questions\"]}'\n",
    "        try:\n",
    "            response = get_code_completion(prompt, model, tokenizer, temperature)\n",
    "            print(f\"Traversing index at: {i}\")\n",
    "            print(response)\n",
    "            processed_df = processed_df.append({\"prompt\":prompt, \"output\": response}, ignore_index=True)\n",
    "#             processed_df = processed_df.append({\"content\":row[\"content\"],\"question\": row[\"multiple_questions\"], \"output\": response}, ignore_index=True)\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                processed_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "#             print(len(str(e)))\n",
    "            print(f\"Error encountered at row {i}: {str(e)}. Waiting 2 minutes before retrying...\")\n",
    "            traceback.print_exc()\n",
    "            time.sleep(120)\n",
    "\n",
    "    processed_df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "    print(\"Generation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706411f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaTokenizerFast(name_or_path='Kamyar-zeinalipour/TR_QUIZ_GEN_MULTI_LLAMA7B', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "[WARNING] DEVICE(1578,ffffb50110b0,python):2025-02-16-17:29:05.080.934 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_vmm_adapter.h:188] CheckVmmDriverVersion] Driver version is less than 24.0.0, vmm is disabled by default, drvier_version: 23.0.6\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:14<00:00, 37.47s/it]\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/configuration_utils.py:557: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/configuration_utils.py:557: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model OK\n",
      "Total row:-1\n",
      "Row Number: 0\n",
      "input_ids dtype: Int64\n",
      "Traversing index at: 0\n",
      "<s> content,multiple_questionsnan,nan,nan\n",
      "You are a\n",
      "Row Number: 1\n",
      "input_ids dtype: Int64\n",
      "Traversing index at: 1\n",
      "<s> Standart olmayan şartlardaki hücre potansiyelidir. Aynı hücrenin standart şartlardaki hücre potansiyelidir.n:  Tepkimede alınan veya verilen elektron sayısıdır.Q: Tepkime oranıdır (Denge sabiti).\n",
      "tepkimesinde bir pilin potansiyeli genel olarak\n",
      "eşitliğiyle hesaplanır. Bu eşitlikte  ve   deney şartlarındaki   ve    iyonlarının derişimleridir.,\"Question 1: Nernst Eşitliği hangi durumu hesaplamak için kullanılır?nan:  Teknolojik\n",
      "Row Number: 2\n",
      "input_ids dtype: Int64\n",
      "Traversing index at: 2\n",
      "<s> Choices: A. Standart olmayan şartlardaki hücre potansiyelini, B. Tepkime oranını, C. Elektron sayısınınan hücredeki enerji d\n",
      "Row Number: 3\n",
      "input_ids dtype: Int64\n",
      "Traversing index at: 3\n",
      "<s> Right Answer: Standart olmayan şartlardaki hücre potansiyelini\"nanopatent\" adını\n",
      "Row Number: 4\n",
      "input_ids dtype: Int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR] PRE_ACT(1578,ffff417ea1e0,python):2025-02-16-17:31:27.214.234 [mindspore/ccsrc/backend/common/mem_reuse/abstract_dynamic_mem_pool.cc:316] ExpandBlock] Expand block failed, expand size : 0.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1578/2841708995.py\", line 24, in generate_code_completions\n",
      "    response = get_code_completion(prompt, model, tokenizer, temperature)\n",
      "  File \"/tmp/ipykernel_1578/2579591544.py\", line 14, in get_code_completion\n",
      "    outputs = model.generate(\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/peft/peft_model.py\", line 667, in generate\n",
      "    outputs = self.base_model.generate(**kwargs)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/core/utils/_contextlib.py\", line 117, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/utils.py\", line 2024, in generate\n",
      "    result = self._sample(\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/utils.py\", line 3046, in _sample\n",
      "    next_token_scores = logits_processor(input_ids, next_token_logits)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/logits_process.py\", line 85, in __call__\n",
      "    scores = processor(input_ids, scores)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/logits_process.py\", line 1019, in __call__\n",
      "    banned_batch_tokens = _calc_banned_ngram_tokens(self.ngram_size, input_ids, num_batch_hypotheses, cur_len)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/logits_process.py\", line 959, in _calc_banned_ngram_tokens\n",
      "    generated_ngrams = _get_ngrams(ngram_size, prev_input_ids, num_hypos)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindnlp/transformers/generation/logits_process.py\", line 920, in _get_ngrams\n",
      "    gen_tokens = prev_input_ids[idx].tolist()\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/common/tensor.py\", line 3773, in tolist\n",
      "    return self.asnumpy().tolist()\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/common/_stub_tensor.py\", line 49, in fun\n",
      "    return method(*arg, **kwargs)\n",
      "  File \"/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/mindspore/common/tensor.py\", line 1070, in asnumpy\n",
      "    return Tensor_.asnumpy(self)\n",
      "RuntimeError: Allocate memory failed\n",
      "\n",
      "----------------------------------------------------\n",
      "- C++ Call Stack: (For framework developers)\n",
      "----------------------------------------------------\n",
      "mindspore/ccsrc/runtime/device/device_address_utils.cc:1299 MallocForOutputs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during code generation: Allocate memory failed\n",
      "\n",
      "----------------------------------------------------\n",
      "- C++ Call Stack: (For framework developers)\n",
      "----------------------------------------------------\n",
      "mindspore/ccsrc/runtime/device/device_address_utils.cc:1299 MallocForOutputs\n",
      "\n",
      "Error encountered at row 4: Allocate memory failed\n",
      "\n",
      "----------------------------------------------------\n",
      "- C++ Call Stack: (For framework developers)\n",
      "----------------------------------------------------\n",
      "mindspore/ccsrc/runtime/device/device_address_utils.cc:1299 MallocForOutputs\n",
      ". Waiting 2 minutes before retrying...\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Main entry point\"\"\"\n",
    "    temperature=0.2\n",
    "    model_path = \"Kamyar-zeinalipour/TR_QUIZ_GEN_MULTI_LLAMA7B\"\n",
    "    input_file = \"Train-dataset.csv\"\n",
    "    output_file = \"result.csv\"\n",
    "    ms.ms_memory_recycle()\n",
    "    ms.set_context(memory_optimize_level='O0' )  # 启用内存优化\n",
    "    model, tokenizer = load_model(model_path)\n",
    "    ms.ms_memory_recycle()\n",
    "    # ms.memory_reporter()\n",
    "    generate_code_completions(model, tokenizer,input_file,output_file,temperature)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75316ba0-d0f2-4983-ba45-dc482a81ec76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
